# READ THIS
# The Travis CI environment needs to have the following defined:
# 1. CLOWDER_HOST_URI - the Clowder host URI to test against. Needs to be clean for each testing run (no post-
#    run cleanup is done at this time)
# 2. TEST_DATASET_NAME - the name of the dataset to create and use for testing
# 3. DOCKER_COMPOSE_VERSION - the version of docker-compose to install

# Superuser for docker commands and such
sudo: required

# python environment and python version
language: python
python: 
  - "3.6"
cache: pip

# What sources to auto build
branches:
  only:
  - master
  - develop
  - "/.*travis.*/" # indicates a Travis CI test
  - "/^\\d+\\.\\d+(\\.\\d+)?(-\\S*)?$/" # tagged branches

# We're using docker
services:
  - docker

# Only deploy the container after the master branch has built
stages:
  - name: after_script
    # require the branch name to be master (note for PRs this is the base branch name)
    if: branch = master

env:
  global:
    - DOCKER_NAMED_CONTAINER=test_extractor   # Used to name the container for easier finding
    - EXTRACTOR_DOCKER_NAME=chrisatua/extractors:opendronemap
    - EXTRACTOR_REGISTRATION_FILE=pipelineutils/pytest/data/opendronemap_extractor_info.json
    - TEST_SOURCE_ARCHIVE=odm_test_data.tar
    - SOURCE_FILE=pipelineutils/pipelineutils/pipelineutils.py
    - TEST_CLOWDER_USERNAME=test@example.com
    - TEST_CLOWDER_PASSWORD=testPassword
    - TEST_EXTRACTOR_NAME=opendronemap
    - TEST_SPACE_NAME=test_space
    - TEST_FILE_UPLOAD_PATH=pipelineutils/pytest/data/opendronemap_extractor_info.json
    - TEST_EXTRACTOR_FULL_NAME=terra.dronepipeline.opendronemap
    # Secured Pypi credentials 
    - secure: "XUFznRRIo3V6dkkTxq3UsQFhnfyN+Jd6Aee2zK48/wB407US9FzqCUEuUtSvI0i7O8NvyyJNJ8/zViuHXz37go3bqyjd6ovkAlMaKuWhxFbZWU6f2F1PTOd9ON3GJ/JAVHhlElQczeKKCYeQwWIEECbFKwdzcFUs9XPdkurfozxGlqCjIfQdSNMoCTySPMmhycWzHCi/Z3wQenUBsn+B8JlJ9GlIWZ8u/fmn+BflCAGhmlvQ6W2sGOgZCRF4p6MLr/8+2eWBLpCjuJqvDfBZTkaFDhrmI02D13l2Pz0o4gvbuUb3pDkPLRbWXC+j56NNfZv/JZyFzAya0gRogPj8QTrLHe+vU2wdHQ5y60hyTAjsZPiKy7g3+gTolOAY2S+587pkKu8BiLNd/HT4mM3P1o8Y+1lMs7dpCbvjfzCujJZM3GbkEoOXlElxa+/h12CPNz9890qaUbrd8NN5a0VuUtSB72Y6+mlifbFRk8kgzmNTMJ0O5oHakqKA6jX7q1Ey0ZlkK5meVfkpNg/mMwQCk657h7BAq5QNgeI9OqgS+eIlmZ6CdjKB+mNn1ZLhDa6Zm3s+p0oduvRqFHDVaulkXqyWoPewjpzsaddmJc49FxpfHAzVO5mJPCHpZu5G4XYrUhXFFG9ElULRnPgGqabCDccyVr7JwmMukfl7j1LGuUw="
    - secure: "nRvO7ajFrnVd/HSpKWaUo/I3SU/QcXssItv/Nz7BOgSEOWU3Y/CCLPQdaD/huHSZpfRA5cx94uI3TE1qh4yPMyVTPV8DMwoNRies1C9nAm8C/DFmVgaYowg2J1qpNh5aoLkWqR+JV4Gvv66jYOZTzsCm7oyUDOlO2tdejIVAC1iBSpPsxMXr459Q4QfNPQL6fre5jY3fuAqH98708VTuuUvTU/Rs5Bm1sgnMBp7FpZITD1GfKFDHGpGAxn9/+OD8HkWKgVoaZmocYjS8Y0yDbQSe3ORnhOOq/hlPKsQ4MbP8B1gSA8LDOHwvV/Y6eISNda/MIOwFX6cGuCGsdMjHXUEvtsEtWS3p93L7u/XSEbcQKIbwnS95OwwCaAFyecCH/ggdLKhpOAp6XEMgATd1hqUQ74plXLS+9IKhOP3TL+bSkkUrEaQwhFot7TMGclfv2aURF6COxnVBmWYcPRXLp+S6c2hewMDo8WuXLrdcYDQLKtfAIvM8dAcQ5QNR3duQs4qUPvISseJVUhFeXsH8wPRCWSwcMFKr7FN4C9WF+X3p63oKQ+mnlSVyMqfeRDTSRI8Ys0ObbWTGxhWYWt00CVyEBzsnB6Xw42H7QUChM6pOKuLbZbbB3S9iVmDrM+Rv1L6VVxBij+c8pMD6URE/3RoBqKHjDOIlg36vHj3fNVE="


# Basic setup for the build. Install software needed by all extractors followed by optional installs for specific extractors
before_install:
  - export BRANCH=$(if [ "$TRAVIS_PULL_REQUEST" == "false" ]; then echo $TRAVIS_BRANCH; else echo $TRAVIS_PULL_REQUEST_BRANCH; fi)
  - echo "Travis branch name is:\ $BRANCH"
  - echo "Displaying basic environment information"
  - docker --version
  - ls -l
  - ls -l test
  - ls -l pipelineutils
  - ls -l pipelineutils/pytest
  - ls -l pipelineutils/pipelineutils
  - echo "Attempting to update to docker-compose version:\ $DOCKER_COMPOSE_VERSION"
  - sudo rm -f /usr/local/bin/docker-compose   # Update docker-compose by removing any old versions
  - curl -L https://github.com/docker/compose/releases/download/$DOCKER_COMPOSE_VERSION/docker-compose-`uname -s`-`uname -m` > docker-compose
  - chmod +x docker-compose
  - ls -l docker-compose     # Show that docker-compose is in place with correct permissions
  - sudo mv docker-compose /usr/local/bin  # Put into correct spot
  - docker-compose --version
  # Install packages that are needed
  # Install Python packages that are needed
  - pip install -U pylint
  - pip install -U requests
  - pip install -U uuid

# Start up the test bed containers and copy files from other locations as needed
install:
  - echo "Starting up environment with docker-compose"
  - docker-compose -p clowder -f test/docker-compose.yml up -d
  - docker images
  - docker ps -a
  - docker inspect clowder_clowder_1
  - ./test/wait_for_clowder.sh
  # Setup the clowder account
  - echo "Starting Clowder configuration"
  - echo "Clowder URL:\ $CLOWDER_HOST_URI"
  - curl -X POST -H "Content-Type:application/x-www-form-urlencoded" "$CLOWDER_HOST_URI/signup?email=$TEST_CLOWDER_USERNAME"
  - ./test/wait_for_registration.sh
  - URI=`sed -r 's/.*href="(.+)">.*/\1/' reg.txt`
  - echo "URI:\ $URI"
  - curl -X POST -H "Content-Type:application/x-www-form-urlencoded" "$URI?firstName=test&lastName=test&password.password1=$TEST_CLOWDER_PASSWORD&password.password2=$TEST_CLOWDER_PASSWORD&agreementAcknowledged=true"
  - curl -X POST -H "Content-Type:application/x-www-form-urlencoded" "$CLOWDER_HOST_URI/authenticate/userpass?username=$TEST_CLOWDER_USERNAME&password=$TEST_CLOWDER_PASSWORD" -D headers.txt
  - USER_ID=`grep 'Set-Cookie:\ id' headers.txt | sed -r 's/Set-(.+);.*;.*/\1/'`
  - echo "USER ID:\ $USER_ID"
  - export API_KEY=`curl -X POST -v -H "Content-Type:application/x-www-form-urlencoded" "$CLOWDER_HOST_URI/api/users/keys?name=testingkey" -H "$USER_ID" | sed -r 's/.*"key":"(.+)".*/\1/'`
  - echo "API KEY:\ $API_KEY"

# Setup the clowder environment
before_script:
  - echo "Setting up Clowder spaces and datasets"
  - export SPACE_ID=`curl -X POST -v -H "accept:application/json" -H "Content-Type:application/json" -d "{\"name\":\"$TEST_SPACE_NAME\",\"description\":\"Test results\"}" "$CLOWDER_HOST_URI/api/spaces?key=$API_KEY" | sed -r 's/.*id\"\:\"(.+)\".*/\1/'`
  - echo "SPACE_ID:\ $SPACE_ID"
  - export DATASET_ID=`curl -X POST -v -H "accept:application/json" -H "Content-Type:application/json" -d "{\"name\":\"$TEST_DATASET_NAME\"}" "$CLOWDER_HOST_URI/api/datasets/createempty?key=$API_KEY" | sed -r 's/.*id\"\:\"(.+)\".*/\1/'`
  - echo "DATASET ID:\ $DATASET_ID"
  - echo "Running the extractor to test:\ $EXTRACTOR_DOCKER_NAME"
  - docker run --network clowder_clowder -e 'RABBITMQ_URI=amqp://rabbitmq/%2F' -e 'RABBITMQ_EXCHANGE=terra' -d "--name=$DOCKER_NAMED_CONTAINER" "$EXTRACTOR_DOCKER_NAME"
  - echo "Loading data data for the extractor test"
  - ./test/extract.sh "test/$TEST_SOURCE_ARCHIVE"  # Uncompress the test files
  - ls -l ./data
  - ./test/upload_data.py                     # Put the files into clowder
  - echo "Registering the extractor and waiting for it to start"
  - ./test/register_extractor.py "$EXTRACTOR_REGISTRATION_FILE"
  - ./test/wait_for_started.py "$EXTRACTOR_DOCKER_NAME"
  # HACK: This next statement gets Clowder to return the space when queried through the API
  - curl -X GET -H "accept:application/json" "$CLOWDER_HOST_URI/spaces/$SPACE_ID?key=$API_KEY"

# Run the tests
script:
  # First make sure the code is proper
  - pylint --version
  - pylint --rcfile pylint.rc "$SOURCE_FILE"
  - pylint --rcfile pylint.rc pipelineutils/pytest/test_clowder.py
  - echo `curl -X GET -H "accept:application/json" "$CLOWDER_HOST_URI/api/spaces?key=$API_KEY"`
  # Next, run the testing scripts
  - python -m unittest pipelineutils/pytest/test_clowder.py

after_script:
  - echo "Deploying library after successful run"
  - pip install -U setuptools
  - pip install -U wheel
  - pip install -U twine
  - pushd pipelineutils
  - python3 setup.py sdist bdist_wheel
  - /bin/bash -c "if [[ \"$BRANCH\" = \"develop\" ]]; then python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*; echo \"Pushing develop to legacy Pypi\"; else echo \"Taking no actions\"; fi; "
  - /bin/bash -c "if [[ \"$BRANCH\" = \"master\" ]]; then python3 -m twine upload dist/*; echo \"Pushing master to Pipy\"; else echo \"Taking no actions\"; fi; "
  
